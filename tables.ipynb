{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b5ca463-6198-47fe-9e07-01a78aec7847",
   "metadata": {},
   "source": [
    "## Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e27f2b0-63e5-4465-b005-93530010f32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " t_v  ∑ dN_i(t_v)  ∑ ​I(8 ≤ r_i) dN_i(t_v)  ∑ Y_i(t_v)  ∑ ​I(8 ≤ r_i) Y_i(t_v)\n",
      "  12            2                        0          16                      10\n",
      "  13            2                        0          17                      13\n",
      "  15            3                        3          22                      20\n",
      "  16            4                        3          20                      18\n",
      "  17            2                        1          16                      15\n",
      "  18            6                        6          14                      14\n",
      "  19            1                        1           8                       8\n",
      "  20            2                        2           7                       7\n",
      "  21            2                        2           5                       5\n",
      "  22            1                        1           3                       3\n",
      "  23            2                        2           2                       2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "###############################################################################\n",
    "# 0)  CONFIG\n",
    "###############################################################################\n",
    "S_FOCAL = 8                     # “s = 8” in the paper\n",
    "REDUCED_FILE = \"proper_OR.csv\"    # path to the proper‑OR file you generated\n",
    "\n",
    "###############################################################################\n",
    "# 1)  READ  &  PARSE  (r , z)\n",
    "###############################################################################\n",
    "df = pd.read_csv(REDUCED_FILE)\n",
    "\n",
    "# the third column looks like \"(7, 12)\" → split it into integers\n",
    "def parse_pair(txt):\n",
    "    r, z = map(int, re.findall(r\"\\d+\", txt))\n",
    "    return pd.Series({\"r\": r, \"z\": z})\n",
    "\n",
    "df[[\"r\", \"z\"]] = df.iloc[:, 2].apply(parse_pair)\n",
    "\n",
    "###############################################################################\n",
    "# 2)  BUILD THE TABLE\n",
    "###############################################################################\n",
    "records = []\n",
    "for t_v in sorted(df[\"z\"].unique()):          # 11 unique 2→3 times\n",
    "    # Number of 2→3 events at t_v\n",
    "    dN = (df[\"z\"] == t_v).sum()\n",
    "\n",
    "    # … among those who were still in state 1 at s = 8  (⇔  r_i ≥ 8)\n",
    "    dN_s8 = ((df[\"z\"] == t_v) & (df[\"r\"] >= S_FOCAL)).sum()\n",
    "\n",
    "    # Risk set just before t_v:  r_i < t_v  &  z_i ≥ t_v\n",
    "    at_risk = (df[\"r\"] < t_v) & (df[\"z\"] >= t_v)\n",
    "    Y  = at_risk.sum()\n",
    "\n",
    "    # … and who were in state 1 at s = 8\n",
    "    Y_s8 = (at_risk & (df[\"r\"] >= S_FOCAL)).sum()\n",
    "\n",
    "    records.append((t_v, dN, dN_s8, Y, Y_s8))\n",
    "\n",
    "table3 = pd.DataFrame(\n",
    "    records,\n",
    "    columns=[\n",
    "        \"t_v\",\n",
    "        r\"∑ dN_i(t_v)\",\n",
    "        r\"∑ ​I(8 ≤ r_i) dN_i(t_v)\",\n",
    "        r\"∑ Y_i(t_v)\",\n",
    "        r\"∑ ​I(8 ≤ r_i) Y_i(t_v)\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# 3)  DISPLAY\n",
    "###############################################################################\n",
    "print(table3.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66327d3c-7625-4db7-8fda-78cc89a1d701",
   "metadata": {},
   "source": [
    "## Table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90eeff4d-01ec-4514-9ee3-d15e03ebab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improper OR=Improper MI  multiplicity  reduced       p\n",
      "        (9,10) × (23,∞)             2 (10, 23)  0.0639\n",
      "       (10,11) × (23,∞)             7 (11, 23)  0.1649\n",
      "       (11,12) × (23,∞)             1 (12, 23)  0.0379\n",
      "       (12,13) × (23,∞)             7 (13, 23)  0.1682\n",
      "       (14,15) × (23,∞)             8 (15, 23)  0.1548\n",
      "       (15,16) × (23,∞)             5 (16, 23)  0.0619\n",
      "                  total            30                 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load CSV files\n",
    "improper_or_df = pd.read_csv(\"improper_OR.csv\")\n",
    "improper_mi_df = pd.read_csv(\"improper_MI.csv\")\n",
    "\n",
    "# Extract r from Reduced (r, 23) column\n",
    "reduced_rows = improper_mi_df[\"Reduced (r,23)\"].str.extract(r\"\\((\\d+),\\s*23\\)\").astype(int)\n",
    "improper_mi_df[\"r\"] = reduced_rows[0]\n",
    "\n",
    "# Count multiplicities from improper_OR: match (L, L+1] x (23, ∞)\n",
    "counts = defaultdict(int)\n",
    "for _, row in improper_or_df.iterrows():\n",
    "    L, R, W = row['L'], row['R'], row['W']\n",
    "    if W == 23 and R == L + 1:\n",
    "        counts[R] += 1  # R is r in (r, 23)\n",
    "\n",
    "# Filter MI rows with matching r and create table format\n",
    "table5_df = improper_mi_df[improper_mi_df[\"r\"].isin(counts.keys())].copy()\n",
    "table5_df[\"multiplicity\"] = table5_df[\"r\"].map(counts)\n",
    "table5_df[\"Improper OR=Improper MI\"] = table5_df[\"r\"].apply(lambda r: f\"({r-1},{r}) × (23,∞)\")\n",
    "table5_df[\"reduced\"] = table5_df[\"r\"].apply(lambda r: f\"({r}, 23)\")\n",
    "\n",
    "# Final table with desired columns\n",
    "table5 = table5_df[[\"Improper OR=Improper MI\", \"multiplicity\", \"reduced\", \"p\"]].copy()\n",
    "\n",
    "# Optional: add total row\n",
    "total_multiplicity = table5[\"multiplicity\"].sum()\n",
    "table5.loc[\"total\"] = [\"total\", total_multiplicity, \"\", \"\"]\n",
    "\n",
    "# Print the table\n",
    "print(table5.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c85c0-a740-4859-80bb-e1035e2ae235",
   "metadata": {},
   "source": [
    "## Table 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1ce895-0e0a-497a-82c7-6b7f567a3608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Improper OR       Improper MI  multiplicity reduced (r,23)\n",
      "  (1,7) × (23,∞)   (5,7] × (23, ∞)             1         (7,23)\n",
      "  (5,7) × (23,∞)   (5,7] × (23, ∞)             2         (7,23)\n",
      "  (7,9) × (23,∞)   (8,9] × (23, ∞)             1         (9,23)\n",
      "(12,14) × (23,∞) (12,13] × (23, ∞)             2        (13,23)\n",
      "(13,15) × (23,∞) (14,15] × (23, ∞)             3        (15,23)\n",
      "           total                               9               \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Load ---\n",
    "or_df = pd.read_csv(\"improper_OR.csv\")      # columns: L, R, W, Z\n",
    "mi_df = pd.read_csv(\"improper_MI.csv\")      # columns: Improper MI, p, Reduced (r,23)\n",
    "\n",
    "# --- Parse MI endpoints from strings like \"(5,7] × (23, ∞)\" ---\n",
    "uv = mi_df[\"Improper MI\"].str.extract(r\"\\((\\d+)\\s*,\\s*(\\d+)\\]\")\n",
    "mi_df[\"u\"] = uv[0].astype(int)\n",
    "mi_df[\"v\"] = uv[1].astype(int)\n",
    "mi_keep = mi_df[[\"u\", \"v\", \"Improper MI\", \"Reduced (r,23)\"]].copy()\n",
    "\n",
    "# --- Candidate improper ORs: W==23 (improper); we’ll later split adjacent vs non-adjacent ---\n",
    "cand_or = or_df[or_df[\"W\"] == 23][[\"L\", \"R\"]].drop_duplicates()\n",
    "\n",
    "# --- Containment: Type 1 = contains exactly one improper MI ---\n",
    "cross = cand_or.merge(mi_keep, how=\"cross\")\n",
    "contained = cross[(cross[\"L\"] <= cross[\"u\"]) & (cross[\"v\"] <= cross[\"R\"])]\n",
    "\n",
    "# Count # of improper MIs each OR contains\n",
    "mi_counts = contained.groupby([\"L\", \"R\"]).size().reset_index(name=\"num_improper_MI\")\n",
    "\n",
    "# Keep only Type-1 ORs (exactly one improper MI)\n",
    "type1_or = mi_counts[mi_counts[\"num_improper_MI\"] == 1][[\"L\", \"R\"]]\n",
    "\n",
    "# --- Table 6 subset: NOT of the form (L, L+1) ---\n",
    "table6_or = type1_or[type1_or[\"R\"] != type1_or[\"L\"] + 1]\n",
    "\n",
    "# Attach the unique MI row for each selected OR\n",
    "one_mi_detail = table6_or.merge(contained, on=[\"L\", \"R\"], how=\"left\")\n",
    "\n",
    "# Multiplicity of each OR in raw data (how many times it appears with W=23)\n",
    "mult = (or_df[or_df[\"W\"] == 23]\n",
    "        .groupby([\"L\", \"R\"]).size().reset_index(name=\"multiplicity\"))\n",
    "\n",
    "# Build Table 6\n",
    "final = (one_mi_detail.merge(mult, on=[\"L\", \"R\"], how=\"left\")\n",
    "         .drop_duplicates(subset=[\"L\",\"R\"])            # exactly one MI per OR\n",
    "         .sort_values(by=[\"R\", \"L\"])\n",
    "         .assign(\n",
    "             **{\n",
    "                 \"Improper OR\":    lambda d: d.apply(lambda r: f\"({r.L},{r.R}) × (23,∞)\", axis=1),\n",
    "                 \"reduced (r,23)\": lambda d: d[\"Reduced (r,23)\"],\n",
    "             }\n",
    "         )[[\"Improper OR\", \"Improper MI\", \"multiplicity\", \"reduced (r,23)\"]]\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "# Add total row — multiplicities should sum to 9\n",
    "table6 = pd.concat(\n",
    "    [final, pd.DataFrame([[\"total\", \"\", final[\"multiplicity\"].sum(), \"\"]], columns=final.columns)],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "print(table6.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a8411-abfe-4f02-beb6-4119c8a8d7a2",
   "metadata": {},
   "source": [
    "## Table 6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b17613-3179-4556-ae5b-2cc137730db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " t_v  ∑ dN_i(t_v)  ∑ I(8 ≤ r_i) dN_i(t_v)   ∑ Y_i(t_v) ∑ I(8 ≤ r_i) Y_i(t_v)\n",
      "  12            2                       0 16 + 13 = 29          10 + 10 = 20\n",
      "  13            2                       0 17 + 14 = 31          13 + 11 = 24\n",
      "  15            3                       3 22 + 23 = 45          20 + 20 = 40\n",
      "  16            4                       3 20 + 34 = 54          18 + 31 = 49\n",
      "  17            2                       1 16 + 39 = 55          15 + 36 = 51\n",
      "  18            6                       6 14 + 39 = 53          14 + 36 = 50\n",
      "  19            1                       1  8 + 39 = 47           8 + 36 = 44\n",
      "  20            2                       2  7 + 39 = 46           7 + 36 = 43\n",
      "  21            2                       2  5 + 39 = 44           5 + 36 = 41\n",
      "  22            1                       1  3 + 39 = 42           3 + 36 = 39\n",
      "  23            2                       2  2 + 39 = 41           2 + 36 = 38\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------\n",
    "# 1) Load inputs\n",
    "# -------------------------\n",
    "table3 = pd.read_csv(\"table3.csv\")\n",
    "table5 = pd.read_csv(\"table5.csv\")\n",
    "table6 = pd.read_csv(\"table6.csv\")\n",
    "\n",
    "# -------------------------\n",
    "# 2) Helpers\n",
    "# -------------------------\n",
    "def find_col(df, substrings):\n",
    "    \"\"\"Return the first column whose name contains ALL substrings (case-insensitive).\"\"\"\n",
    "    subs = [s.lower() for s in substrings]\n",
    "    for c in df.columns:\n",
    "        cl = c.lower()\n",
    "        if all(s in cl for s in subs):\n",
    "            return c\n",
    "    raise KeyError(f\"Column with substrings {substrings} not found in {list(df.columns)}\")\n",
    "\n",
    "def extract_r(val):\n",
    "    \"\"\"Extract integer r from '(r,23)' allowing spaces.\"\"\"\n",
    "    if not isinstance(val, str):\n",
    "        return None\n",
    "    m = re.search(r\"\\((\\d+)\\s*,\\s*23\\)\", val)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# -------------------------\n",
    "# 3) Parse reduced points & multiplicities from Tables 5 & 6\n",
    "# -------------------------\n",
    "col_mult_5 = find_col(table5, [\"multiplicity\"])\n",
    "col_red_5  = find_col(table5, [\"reduced\"])            # e.g., \"reduced\"\n",
    "r_mult_5 = (\n",
    "    table5.assign(r=table5[col_red_5].apply(extract_r))\n",
    "          .dropna(subset=[\"r\"])\n",
    "          [[\"r\", col_mult_5]]\n",
    "          .rename(columns={col_mult_5: \"multiplicity\"})\n",
    ")\n",
    "\n",
    "col_mult_6 = find_col(table6, [\"multiplicity\"])\n",
    "col_red_6  = find_col(table6, [\"reduced\"])            # e.g., \"reduced (r,23)\"\n",
    "r_mult_6 = (\n",
    "    table6.assign(r=table6[col_red_6].apply(extract_r))\n",
    "          .dropna(subset=[\"r\"])\n",
    "          [[\"r\", col_mult_6]]\n",
    "          .rename(columns={col_mult_6: \"multiplicity\"})\n",
    ")\n",
    "\n",
    "# Combine 5 & 6, then aggregate multiplicities per r\n",
    "r_mult = (\n",
    "    pd.concat([r_mult_5, r_mult_6], ignore_index=True)\n",
    "      .groupby(\"r\", as_index=False)[\"multiplicity\"].sum()\n",
    "      .sort_values(\"r\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Precompute cumulative sums over r for fast lookups of r < t_v\n",
    "r_mult[\"cum_all\"]  = r_mult[\"multiplicity\"].cumsum()\n",
    "r_mult[\"ge8\"]      = (r_mult[\"r\"] >= 8).astype(int) * r_mult[\"multiplicity\"]\n",
    "r_mult[\"cum_ge8\"]  = r_mult[\"ge8\"].cumsum()\n",
    "\n",
    "def cum_less_than(tv, colname):\n",
    "    \"\"\"Cumulative sum of selected multiplicities for all r < tv.\"\"\"\n",
    "    eligible = r_mult[r_mult[\"r\"] < tv]\n",
    "    return int(eligible[colname].iloc[-1]) if not eligible.empty else 0\n",
    "\n",
    "# -------------------------\n",
    "# 4) Read needed columns from Table 3 and build Table 6a\n",
    "# -------------------------\n",
    "col_tv      = find_col(table3, [\"t_v\"])\n",
    "col_dN      = find_col(table3, [\"∑\", \"dn\"])              # \"∑ dN_i(t_v)\"\n",
    "col_I8dN    = find_col(table3, [\"∑\", \"i(8\", \"dn\"])       # \"∑ I(8 ≤ r_i) dN_i(t_v)\"\n",
    "col_Y       = find_col(table3, [\"∑\", \"y_i\"])             # \"∑ Y_i(t_v)\"\n",
    "col_I8Y     = find_col(table3, [\"∑\", \"i(8\", \"y_i\"])      # \"∑ I(8 ≤ r_i) Y_i(t_v)\"\n",
    "\n",
    "rows = []\n",
    "for _, r in table3.iterrows():\n",
    "    tv    = int(r[col_tv])\n",
    "    dN    = int(r[col_dN])\n",
    "    I8dN  = int(r[col_I8dN])\n",
    "    Y0    = int(r[col_Y])\n",
    "    I8Y0  = int(r[col_I8Y])\n",
    "\n",
    "    add_Y   = cum_less_than(tv, \"cum_all\")   # all r<tv\n",
    "    add_I8Y = cum_less_than(tv, \"cum_ge8\")   # only r>=8, r<tv\n",
    "\n",
    "    rows.append({\n",
    "        \"t_v\": tv,\n",
    "        \"∑ dN_i(t_v)\": dN,\n",
    "        \"∑ I(8 ≤ r_i) dN_i(t_v)\": I8dN,\n",
    "        \"∑ Y_i(t_v)\": f\"{Y0} + {add_Y} = {Y0 + add_Y}\",\n",
    "        \"∑ I(8 ≤ r_i) Y_i(t_v)\": f\"{I8Y0} + {add_I8Y} = {I8Y0 + add_I8Y}\",\n",
    "    })\n",
    "\n",
    "table6a = pd.DataFrame(rows)\n",
    "\n",
    "# -------------------------\n",
    "# 5) Save result\n",
    "# -------------------------\n",
    "table6a.to_csv(\"table6a.csv\", index=False)\n",
    "print(table6a.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72181c34-a7fc-4621-a229-cf569e6e7783",
   "metadata": {},
   "source": [
    "## Test Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14985ff2-90b7-48ff-a038-4ff86fb628ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    t_v  sum_dN  sum_I_dN  sum_Y  sum_I_Y       U_t\n",
      "0    12     2.0       0.0   29.0     20.0 -1.379310\n",
      "1    13     2.0       0.0   31.0     24.0 -1.548387\n",
      "2    15     3.0       3.0   45.0     40.0  0.333333\n",
      "3    16     4.0       3.0   54.0     49.0 -0.629630\n",
      "4    17     2.0       1.0   55.0     51.0 -0.854545\n",
      "5    18     6.0       6.0   53.0     50.0  0.339623\n",
      "6    19     1.0       1.0   47.0     44.0  0.063830\n",
      "7    20     2.0       2.0   46.0     43.0  0.130435\n",
      "8    21     2.0       2.0   44.0     41.0  0.136364\n",
      "9    22     1.0       1.0   42.0     39.0  0.071429\n",
      "10   23     2.0       2.0   41.0     38.0  0.146341\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- Load & normalize columns ---\n",
    "df = pd.read_csv(\"table6a.csv\").rename(columns={\n",
    "    't_v': 't_v',\n",
    "    '∑ dN_i(t_v)': 'sum_dN',\n",
    "    '∑ I(8 ≤ r_i) dN_i(t_v)': 'sum_I_dN',\n",
    "    '∑ Y_i(t_v)': 'sum_Y',\n",
    "    '∑ I(8 ≤ r_i) Y_i(t_v)': 'sum_I_Y'\n",
    "})\n",
    "\n",
    "def to_number(x):\n",
    "    \"\"\"Extract the numeric total from entries like '16 + 13 = 29' or pass through numbers.\"\"\"\n",
    "    if pd.isna(x): \n",
    "        return pd.NA\n",
    "    if isinstance(x, (int, float)): \n",
    "        return x\n",
    "    s = str(x)\n",
    "    nums = re.findall(r'(-?\\d+(?:\\.\\d+)?)', s)\n",
    "    return float(nums[-1]) if nums else pd.NA\n",
    "\n",
    "for c in ['sum_dN', 'sum_I_dN', 'sum_Y', 'sum_I_Y']:\n",
    "    df[c] = df[c].apply(to_number).astype(float)\n",
    "\n",
    "# --- Compute U(t_v) ---\n",
    "# U(t_v) = sum_I_dN - sum_I_Y * (sum_dN / sum_Y)\n",
    "df['U_t'] = df['sum_I_dN'] - df['sum_I_Y'] * (df['sum_dN'] / df['sum_Y'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b85787b9-893f-4113-b1ed-62eaed5d79cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistics: -3.1905\n"
     ]
    }
   ],
   "source": [
    "# --- Compute total U ---\n",
    "U = df['U_t'].sum()\n",
    "print(f\"Test Statistics: {round(U, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeea73dc-daa3-41ef-89a8-5e08760f0095",
   "metadata": {},
   "source": [
    "## Table 6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7341b45-ac86-4485-a454-c505afa82d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 6b saved to table6b.csv\n",
      "    t_v  n_V  n_{v1}  n_{v1}(n_V - n_{v1})/n_V^2\n",
      "0    12   29      20                    0.214031\n",
      "1    13   31      24                    0.174818\n",
      "2    15   45      40                    0.098765\n",
      "3    16   54      49                    0.084019\n",
      "4    17   55      51                    0.067438\n",
      "5    18   53      50                    0.053400\n",
      "6    19   47      44                    0.059756\n",
      "7    20   46      43                    0.060964\n",
      "8    21   44      41                    0.063533\n",
      "9    22   42      39                    0.066327\n",
      "10   23   41      38                    0.067817\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === Load the input table (Table 6a stats) ===\n",
    "df = pd.read_csv(\"table6a_stats.csv\")\n",
    "\n",
    "# Extract relevant columns\n",
    "tv = df[\"t_v\"].astype(int)         # time values\n",
    "nV = df[\"sum_Y\"].astype(int)       # n_V = sum of Y_i(t_v)\n",
    "nv1 = df[\"sum_I_Y\"].astype(int)    # n_{v1} = sum of I(8 <= r_i) Y_i(t_v)\n",
    "\n",
    "# Compute the formula: n_{v1}(n_V - n_{v1}) / n_V^2\n",
    "value = nv1 * (nV - nv1) / (nV ** 2)\n",
    "\n",
    "# Build Table 6b DataFrame\n",
    "table6b = pd.DataFrame({\n",
    "    \"t_v\": tv,\n",
    "    \"n_V\": nV,\n",
    "    \"n_{v1}\": nv1,\n",
    "    \"n_{v1}(n_V - n_{v1})/n_V^2\": value.round(6)\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "table6b.to_csv(\"table6b.csv\", index=False)\n",
    "\n",
    "print(\"Table 6b saved to table6b.csv\")\n",
    "print(table6b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d612dd7-6b7d-4ac7-8211-de9e0f08d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Test Statistics: -3.1733\n"
     ]
    }
   ],
   "source": [
    "# --- Compute standardized test statistic ---\n",
    "df[\"var_term\"] = df.apply(lambda row: (row[\"sum_I_Y\"] * (row[\"sum_Y\"] - row[\"sum_I_Y\"])) / (row[\"sum_Y\"]**2) if row[\"sum_Y\"] > 0 else 0, axis=1)\n",
    "V_U = df[\"var_term\"].sum()\n",
    "\n",
    "U_std = U / np.sqrt(V_U) if V_U > 0 else np.nan\n",
    "\n",
    "print(f\"Standardized Test Statistics: {round(U_std, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b48e9c-6280-4bb6-a1e9-d2969cf51ab5",
   "metadata": {},
   "source": [
    "## Table 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ba828c6-55ca-4baf-97cb-af785b255ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 7 (type 2 improper ORs) saved to table7.csv\n",
      "Imp OR (L,R]  multiplicity  Total probability (numeric)                                                                  Sum breakdown\n",
      "     (1, 11]             1                       0.2960                                      0.0437 + 0.0235 + 0.0639 + 0.1649 = 0.296\n",
      "     (1, 12]             2                       0.3339                            0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 = 0.3339\n",
      "     (1, 13]             2                       0.5021                   0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 = 0.5021\n",
      "     (1, 14]             3                       0.5021                   0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 = 0.5021\n",
      "     (1, 15]             2                       0.6569          0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 + 0.1548 = 0.6569\n",
      "     (1, 16]             1                       0.7188 0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 + 0.1548 + 0.0619 = 0.7188\n",
      "     (3, 14]             1                       0.5021                   0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 = 0.5021\n",
      "     (3, 15]             1                       0.6569          0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 + 0.1548 = 0.6569\n",
      "     (7, 10]             1                       0.0874                                                       0.0235 + 0.0639 = 0.0874\n",
      "     (7, 15]             1                       0.6132                   0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 + 0.1548 = 0.6132\n",
      "     (8, 10]             1                       0.0874                                                       0.0235 + 0.0639 = 0.0874\n",
      "     (8, 15]             1                       0.6132                   0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 + 0.1548 = 0.6132\n",
      "     (9, 12]             3                       0.2667                                              0.0639 + 0.1649 + 0.0379 = 0.2667\n",
      "    (10, 12]             2                       0.2028                                                       0.1649 + 0.0379 = 0.2028\n",
      "    (10, 15]             1                       0.5258                                     0.1649 + 0.0379 + 0.1682 + 0.1548 = 0.5258\n",
      "    (11, 13]             4                       0.2061                                                       0.0379 + 0.1682 = 0.2061\n",
      "    (13, 16]             1                       0.2167                                                       0.1548 + 0.0619 = 0.2167\n",
      "    (14, 16]             2                       0.2167                                                       0.1548 + 0.0619 = 0.2167\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure Pandas prints full strings without truncation\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# === 1) Load inputs ===\n",
    "improper_or = pd.read_csv(\"improper_OR.csv\")\n",
    "table4 = pd.read_csv(\"table4.csv\")\n",
    "\n",
    "# Clean headers\n",
    "improper_or.columns = [c.strip() for c in improper_or.columns]\n",
    "table4.columns = [c.strip() for c in table4.columns]\n",
    "\n",
    "# === 2) Parse r from Reduced column and convert p ===\n",
    "def extract_r(cell: str) -> int:\n",
    "    m = re.search(r\"\\(\\s*(\\d+)\\s*,\\s*23\\s*\\)\", str(cell))\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse Reduced (r,23): {cell}\")\n",
    "    return int(m.group(1))\n",
    "\n",
    "table4[\"_r\"] = table4[\"Reduced (r,23)\"].apply(extract_r)\n",
    "table4[\"_p\"] = pd.to_numeric(table4[\"p\"], errors=\"coerce\")\n",
    "r_to_p = table4[[\"_r\", \"_p\"]]\n",
    "\n",
    "# === 3) Collapse improper_OR into unique (L,R] with multiplicity ===\n",
    "improper_or[\"L\"] = improper_or[\"L\"].astype(int)\n",
    "improper_or[\"R\"] = improper_or[\"R\"].astype(int)\n",
    "\n",
    "grouped = (\n",
    "    improper_or.groupby([\"L\", \"R\"], as_index=False)\n",
    "    .size()\n",
    "    .rename(columns={\"size\": \"multiplicity\"})\n",
    "    .sort_values([\"L\", \"R\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# === 4) Compute probability sums ===\n",
    "def sum_for_interval(L: int, R: int):\n",
    "    mask = (r_to_p[\"_r\"] > L) & (r_to_p[\"_r\"] <= R)\n",
    "    probs = r_to_p.loc[mask, \"_p\"].dropna().tolist()\n",
    "    total = float(sum(probs))\n",
    "    terms = \" + \".join(f\"{p:.4f}\".rstrip(\"0\").rstrip(\".\") for p in probs)\n",
    "    expr = f\"{terms} = {total:.4f}\".rstrip(\"0\").rstrip(\".\") if terms else \"0 = 0\"\n",
    "    return total, expr, len(probs)\n",
    "\n",
    "totals, exprs, counts = [], [], []\n",
    "for _, row in grouped.iterrows():\n",
    "    total, expr, count = sum_for_interval(int(row[\"L\"]), int(row[\"R\"]))\n",
    "    totals.append(total)\n",
    "    exprs.append(expr)\n",
    "    counts.append(count)\n",
    "\n",
    "grouped[\"Total probability (numeric)\"] = totals\n",
    "grouped[\"Sum breakdown\"] = exprs\n",
    "grouped[\"num_MI_rects\"] = counts\n",
    "\n",
    "# === 5) Keep only type 2 ORs (more than one MI rectangle) ===\n",
    "table7 = grouped[grouped[\"num_MI_rects\"] > 1].copy()\n",
    "\n",
    "# Nicely formatted interval column\n",
    "table7.insert(0, \"Imp OR (L,R]\", table7.apply(lambda r: f\"({int(r['L'])}, {int(r['R'])}]\", axis=1))\n",
    "\n",
    "# Drop helper columns and reset index\n",
    "table7 = table7.drop(columns=[\"L\", \"R\", \"num_MI_rects\"]).reset_index(drop=True)\n",
    "\n",
    "# === 6) Save to CSV ===\n",
    "table7.to_csv(\"table7.csv\", index=False)\n",
    "\n",
    "print(\"Table 7 (type 2 improper ORs) saved to table7.csv\")\n",
    "print(table7.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97bc8e0-17fe-488b-a743-31842839aeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44ecd426-ef8f-4431-99de-e3cd36072c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OR mini-tables     -> out/or_probs/OR_summary.csv\n",
      "✓ Imputed draws      -> out/or_draws/all_draws.csv (rows=0)\n",
      "✓ I*-tables (CSVs)   -> out/I_tables\n",
      "Notes:\n",
      " - If OR blocks are empty, check that 'Sum breakdown' entries numerically contain MI bins in table4.\n",
      " - Add 'yk_patterns.csv' and/or 'mask_by_tv.csv' to control Y_k(t_v) and I(8 ≤ r_i).\n"
     ]
    }
   ],
   "source": [
    "# end_to_end_or_pipeline.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "End-to-end replication of the instruction images:\n",
    "\n",
    "(1) Build OR mini-tables (per OR):\n",
    "    - idx_in_or, MI interval, unconditional prob (from Table 4), conditional prob within OR\n",
    "(2) Impute (draw) MI rectangles for each OR according to 'multiplicity' (Table 7)\n",
    "(3) Generate I*-style indicator tables (I1..I5 + Y9/Y10 blocks)\n",
    "\n",
    "Robust matching:\n",
    "- Normalizes interval labels (whitespace, commas, bracket glyphs)\n",
    "- Matches MI either by exact endpoints OR by containment when Table 7 lists a super-interval\n",
    "- Parses probabilities like \"3.2%\" or \"1,234\"\n",
    "\n",
    "Inputs (place next to this script or edit BASE below):\n",
    "- table4.csv : MUST have columns ['Improper MI','p']\n",
    "- table7.csv : MUST have columns ['Imp OR (L,R]','Sum breakdown'] and optional ['multiplicity']\n",
    "Optional:\n",
    "- yk_patterns.csv : rows 'Y1'.., cols '12'..'23' (0/1) to specify Y_k(t_v)\n",
    "- mask_by_tv.csv  : one row with cols '12'..'23' (0/1) for I(8 ≤ r_i) mask\n",
    "\n",
    "Outputs:\n",
    "- ./out/or_probs/OR*.csv, OR_summary.csv\n",
    "- ./out/or_draws/OR*_draws.csv, all_draws.csv\n",
    "- ./out/I_tables/*.csv\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------- CONFIG -------------------------\n",
    "BASE = Path(\".\")\n",
    "T4_PATH = BASE / \"table4.csv\"\n",
    "T7_PATH = BASE / \"table7.csv\"\n",
    "YK_PATH = BASE / \"yk_patterns.csv\"   # optional\n",
    "MASK_PATH = BASE / \"mask_by_tv.csv\"  # optional\n",
    "\n",
    "OUT = BASE / \"out\"\n",
    "OR_PROB_DIR = OUT / \"or_probs\"\n",
    "OR_DRAW_DIR = OUT / \"or_draws\"\n",
    "I_DIR       = OUT / \"I_tables\"\n",
    "for d in (OR_PROB_DIR, OR_DRAW_DIR, I_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TV_COLS = [str(v) for v in range(12, 24)]  # t_v = 12..23\n",
    "\n",
    "# ------------------------- HELPERS -------------------------\n",
    "def clean_prob(x) -> float:\n",
    "    \"\"\"Parse 'p' values that might include '%' or thousands separators.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip()\n",
    "    if s.endswith(\"%\"):\n",
    "        try:\n",
    "            return float(s[:-1].replace(\",\", \"\")) / 100.0\n",
    "        except:\n",
    "            return np.nan\n",
    "    try:\n",
    "        return float(s.replace(\",\", \"\"))\n",
    "    except:\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def normalize_interval_label(s: str) -> str:\n",
    "    \"\"\"Normalize labels like '(5, 7]' -> '(5,7]'; strip 'MI'/'Improper' prefixes; unify union glyph.\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s0 = str(s).strip()\n",
    "    s0 = re.sub(r\"^\\s*(MI|Improper|Rect|Rectangle)\\s*\", \"\", s0, flags=re.I)\n",
    "    s0 = re.sub(r\"\\s*,\\s*\", \",\", s0)\n",
    "    s0 = (s0.replace(\"（\", \"(\").replace(\"）\", \")\")\n",
    "             .replace(\"，\", \",\").replace(\"［\", \"[\").replace(\"］\", \"]\")\n",
    "             .replace(\"∪\", \"U\").replace(\"u\", \"U\"))\n",
    "    s0 = re.sub(r\"\\s+\", \"\", s0)\n",
    "    return s0\n",
    "\n",
    "def parse_endpoints(label: str) -> Optional[Tuple[str, int, int, str]]:\n",
    "    \"\"\"Return (left_bracket, a, b, right_bracket) for '(a,b]' style; None if not parseable.\"\"\"\n",
    "    lab = normalize_interval_label(label)\n",
    "    m = re.match(r\"^([\\(\\[])\\s*(\\d+)\\s*,\\s*(\\d+)\\s*([\\)\\]])$\", lab)\n",
    "    if not m:\n",
    "        return None\n",
    "    return (m.group(1), int(m.group(2)), int(m.group(3)), m.group(4))\n",
    "\n",
    "def bracket_insensitive_key(label: str) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"Reduce interval to (a,b) ignoring bracket types so '(5,7]' matches '[5,7)' etc.\"\"\"\n",
    "    ep = parse_endpoints(label)\n",
    "    if not ep:\n",
    "        return None\n",
    "    _, a, b, _ = ep\n",
    "    return (a, b)\n",
    "\n",
    "def contains(super_interval: str, sub_interval: str) -> bool:\n",
    "    \"\"\"Check if sub_interval is fully contained in super_interval (numeric only, ignore brackets).\"\"\"\n",
    "    S = parse_endpoints(super_interval)\n",
    "    s = parse_endpoints(sub_interval)\n",
    "    if not S or not s:\n",
    "        return False\n",
    "    _, A, B, _ = S\n",
    "    _, a, b, _ = s\n",
    "    return (A <= a) and (b <= B)\n",
    "\n",
    "def parse_union_list(s: str) -> List[str]:\n",
    "    ss = str(s).replace(\"∪\", \"U\").replace(\"u\", \"U\")\n",
    "    return [normalize_interval_label(p) for p in re.split(r\"\\s*U\\s*\", ss) if p.strip()]\n",
    "\n",
    "# ------------------------- LOAD INPUTS -------------------------\n",
    "# Table 4\n",
    "t4 = pd.read_csv(T4_PATH)\n",
    "if \"Improper MI\" not in t4.columns or \"p\" not in t4.columns:\n",
    "    raise RuntimeError(\"table4.csv must include columns 'Improper MI' and 'p'.\")\n",
    "t4[\"_interval_raw\"]  = t4[\"Improper MI\"]\n",
    "t4[\"_interval_norm\"] = t4[\"_interval_raw\"].map(normalize_interval_label)\n",
    "t4[\"_endpoints_key\"] = t4[\"_interval_norm\"].map(bracket_insensitive_key)\n",
    "t4[\"_prob_raw\"]      = t4[\"p\"]\n",
    "t4[\"_prob\"]          = t4[\"_prob_raw\"].map(clean_prob)\n",
    "\n",
    "# Table 7\n",
    "t7 = pd.read_csv(T7_PATH)\n",
    "if \"Imp OR (L,R]\" not in t7.columns or \"Sum breakdown\" not in t7.columns:\n",
    "    raise RuntimeError(\"table7.csv must include columns 'Imp OR (L,R]' and 'Sum breakdown'.\")\n",
    "t7[\"_or_id\"]         = np.arange(1, len(t7)+1)\n",
    "t7[\"_or_label\"]      = t7[\"Imp OR (L,R]\"].map(normalize_interval_label)\n",
    "t7[\"_or_endpoints\"]  = t7[\"_or_label\"].map(bracket_insensitive_key)\n",
    "t7[\"_multiplicity\"]  = pd.to_numeric(t7.get(\"multiplicity\", 1), errors=\"coerce\").fillna(1).astype(int)\n",
    "t7[\"_components_norm\"] = t7[\"Sum breakdown\"].map(parse_union_list)\n",
    "\n",
    "t4_key_set = set(k for k in t4[\"_endpoints_key\"] if k is not None)\n",
    "\n",
    "# ---------------------- OR BLOCK (ROBUST) ----------------------\n",
    "def robust_or_block(components_norm: List[str], t4_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build an OR block by:\n",
    "      1) exact endpoint matches when the component is an MI bin,\n",
    "      2) otherwise, include all MI rectangles fully contained in the component (super-interval).\n",
    "    \"\"\"\n",
    "    chosen_idx = []\n",
    "    for comp in components_norm:\n",
    "        key = bracket_insensitive_key(comp)\n",
    "        if key and key in t4_key_set:\n",
    "            chosen_idx.extend(t4_df.index[t4_df[\"_endpoints_key\"] == key].tolist())\n",
    "        else:\n",
    "            for j, lab in enumerate(t4_df[\"_interval_norm\"]):\n",
    "                if contains(comp, lab):\n",
    "                    chosen_idx.append(j)\n",
    "    chosen_idx = sorted(set(chosen_idx))\n",
    "    if not chosen_idx:\n",
    "        return pd.DataFrame(columns=[\"idx_in_or\", \"interval\", \"uncond_prob\", \"cond_prob_in_or\"])\n",
    "\n",
    "    sub = t4_df.loc[chosen_idx].copy().reset_index(drop=True)\n",
    "    sub[\"idx_in_or\"] = np.arange(1, len(sub) + 1)\n",
    "    sub[\"interval\"] = sub[\"_interval_norm\"]\n",
    "    sub[\"uncond_prob\"] = sub[\"_prob\"]\n",
    "    total = sub[\"uncond_prob\"].sum(skipna=True)\n",
    "    sub[\"cond_prob_in_or\"] = sub[\"uncond_prob\"] / total if (pd.notna(total) and total > 0) else np.nan\n",
    "    return sub[[\"idx_in_or\", \"interval\", \"uncond_prob\", \"cond_prob_in_or\"]]\n",
    "\n",
    "# -------------------- OR MINI-TABLES & SUMMARY --------------------\n",
    "summary_rows: List[Dict] = []\n",
    "for _, r in t7.iterrows():\n",
    "    oid   = int(r[\"_or_id\"])\n",
    "    comps = r[\"_components_norm\"]\n",
    "    blk   = robust_or_block(comps, t4)\n",
    "    blk.to_csv(OR_PROB_DIR / f\"OR{oid}.csv\", index=False)\n",
    "    summary_rows.append({\n",
    "        \"OR_id\": oid,\n",
    "        \"OR_interval\": r[\"_or_label\"],\n",
    "        \"multiplicity\": int(r[\"_multiplicity\"]),\n",
    "        \"components_count\": len(comps),\n",
    "        \"components_union\": \" ∪ \".join(comps),\n",
    "        \"num_mi_in_or\": int(len(blk)) if not blk.empty else 0,\n",
    "        \"sum_uncond_prob\": float(blk[\"uncond_prob\"].sum()) if not blk.empty else np.nan\n",
    "    })\n",
    "\n",
    "pd.DataFrame(summary_rows).sort_values(\"OR_id\").to_csv(OR_PROB_DIR / \"OR_summary.csv\", index=False)\n",
    "\n",
    "# ---------------------------- IMPUTATION ----------------------------\n",
    "rng = np.random.default_rng(20250910)  # fixed seed for reproducibility\n",
    "draw_records: List[Dict] = []\n",
    "\n",
    "for _, r in t7.iterrows():\n",
    "    oid   = int(r[\"_or_id\"])\n",
    "    mult  = int(r[\"_multiplicity\"])\n",
    "    blk   = robust_or_block(r[\"_components_norm\"], t4)\n",
    "\n",
    "    if blk.empty or mult <= 0:\n",
    "        pd.DataFrame(columns=[\"draw_num\", \"mi_idx_in_or\", \"mi_interval\", \"prob_used\"]).to_csv(\n",
    "            OR_DRAW_DIR / f\"OR{oid}_draws.csv\", index=False\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    probs  = blk[\"cond_prob_in_or\"].to_numpy(dtype=float)\n",
    "    labels = blk[\"interval\"].tolist()\n",
    "    idxs   = blk[\"idx_in_or\"].to_numpy()\n",
    "\n",
    "    # normalize or fallback to uniform\n",
    "    ps = np.nansum(probs)\n",
    "    if not np.isfinite(ps) or ps <= 0:\n",
    "        probs = np.ones_like(probs, dtype=float) / len(probs)\n",
    "    else:\n",
    "        probs = probs / ps\n",
    "\n",
    "    draws = rng.choice(len(labels), size=mult, p=probs, replace=True)\n",
    "\n",
    "    per_or = pd.DataFrame({\n",
    "        \"draw_num\":     np.arange(1, mult+1),\n",
    "        \"mi_idx_in_or\": idxs[draws],\n",
    "        \"mi_interval\":  [labels[d] for d in draws],\n",
    "        \"prob_used\":    probs[draws],\n",
    "    })\n",
    "    per_or.to_csv(OR_DRAW_DIR / f\"OR{oid}_draws.csv\", index=False)\n",
    "\n",
    "    for row2 in per_or.itertuples(index=False):\n",
    "        draw_records.append({\n",
    "            \"OR_id\":        oid,\n",
    "            \"draw_num\":     int(row2.draw_num),\n",
    "            \"mi_idx_in_or\": int(row2.mi_idx_in_or),\n",
    "            \"mi_interval\":  row2.mi_interval,\n",
    "            \"prob_used\":    float(row2.prob_used),\n",
    "        })\n",
    "\n",
    "all_draws = pd.DataFrame(draw_records, columns=[\"OR_id\",\"draw_num\",\"mi_idx_in_or\",\"mi_interval\",\"prob_used\"])\n",
    "if not all_draws.empty:\n",
    "    all_draws = all_draws.sort_values([\"OR_id\",\"draw_num\"])\n",
    "all_draws.to_csv(OR_DRAW_DIR / \"all_draws.csv\", index=False)\n",
    "\n",
    "# ---------------------------- I*-TABLES ----------------------------\n",
    "# Load Yk patterns if available; else default to all ones.\n",
    "YMAP: Dict[str, np.ndarray] = {}\n",
    "if YK_PATH.exists():\n",
    "    yk = pd.read_csv(YK_PATH)\n",
    "    label_col = yk.columns[0]\n",
    "    ok_cols = [c for c in yk.columns if str(c) in TV_COLS]\n",
    "    for _, rr in yk.iterrows():\n",
    "        name = str(rr[label_col]).strip()\n",
    "        m = re.search(r\"(\\d+)\", name)\n",
    "        if not m:\n",
    "            continue\n",
    "        key = f\"Y{int(m.group(1))}\"\n",
    "        vec = rr[ok_cols].to_numpy(dtype=int)\n",
    "        if vec.size == len(TV_COLS):\n",
    "            YMAP[key] = vec\n",
    "else:\n",
    "    for k in range(1, 11):  # default Y1..Y10 = all ones\n",
    "        YMAP[f\"Y{k}\"] = np.ones(len(TV_COLS), dtype=int)\n",
    "\n",
    "# Mask for I(8 ≤ r_i): use mask_by_tv.csv if present; else default step at t_v >= 16\n",
    "if MASK_PATH.exists():\n",
    "    mdf = pd.read_csv(MASK_PATH)\n",
    "    mask = None\n",
    "    for _, rr in mdf.iterrows():\n",
    "        vals = rr[[c for c in mdf.columns if str(c) in TV_COLS]].to_numpy(dtype=int)\n",
    "        if vals.size == len(TV_COLS):\n",
    "            mask = vals\n",
    "            break\n",
    "    mask_I_8_le_r = mask if mask is not None else np.array([1 if int(c) >= 16 else 0 for c in TV_COLS])\n",
    "else:\n",
    "    mask_I_8_le_r = np.array([1 if int(c) >= 16 else 0 for c in TV_COLS], dtype=int)\n",
    "\n",
    "def yrow(ykey: str, masked: bool) -> np.ndarray:\n",
    "    base = YMAP.get(ykey, np.zeros(len(TV_COLS), dtype=int))\n",
    "    return (base & mask_I_8_le_r) if masked else base\n",
    "\n",
    "def write_I(specs: List[Tuple[str, str, bool]], name: str):\n",
    "    rows, idx = [], []\n",
    "    for label, ykey, masked in specs:\n",
    "        rows.append(yrow(ykey, masked))\n",
    "        idx.append(label)\n",
    "    df = pd.DataFrame(rows, columns=TV_COLS, index=idx)\n",
    "    df.to_csv(I_DIR / f\"{name}.csv\")\n",
    "    return df\n",
    "\n",
    "# Row specs from the images\n",
    "I1_specs = [\n",
    "    (\"if 1 ≤ i ≤ 4, Y1(t_v)\", \"Y1\", False),\n",
    "    (\"if i = 1, I(8 ≤ r_i)Y1(t_v)\", \"Y1\", True),\n",
    "    (\"if 2 ≤ i ≤ 4, I(8 ≤ r_i)Y1(t_v)\", \"Y1\", True),\n",
    "]\n",
    "I2_specs = [\n",
    "    (\"if 1 ≤ i ≤ 4, Y2(t_v)\", \"Y2\", False),\n",
    "    (\"if i = 5, Y2(t_v)\", \"Y2\", False),\n",
    "    (\"if i = 1, I(8 ≤ r_i)Y2(t_v)\", \"Y2\", True),\n",
    "    (\"if 2 ≤ i ≤ 4, I(8 ≤ r_i)Y2(t_v)\", \"Y2\", True),\n",
    "    (\"if i = 5, I(8 ≤ r_i)Y2(t_v)\", \"Y2\", True),\n",
    "]\n",
    "I3_specs = [\n",
    "    (\"if 1 ≤ i ≤ 4, Y3(t_v)\", \"Y3\", False),\n",
    "    (\"if i = 5, Y3(t_v)\", \"Y3\", False),\n",
    "    (\"if i = 6, Y3(t_v)\", \"Y3\", False),\n",
    "    (\"if i = 1, I(8 ≤ r_i)Y3(t_v)\", \"Y3\", True),\n",
    "    (\"if 2 ≤ i ≤ 4, I(8 ≤ r_i)Y3(t_v)\", \"Y3\", True),\n",
    "    (\"if i = 5, I(8 ≤ r_i)Y3(t_v)\", \"Y3\", True),\n",
    "    (\"if i = 6, I(8 ≤ r_i)Y3(t_v)\", \"Y3\", True),\n",
    "]\n",
    "I4_specs = [\n",
    "    (\"if 1 ≤ i ≤ 4, Y7(t_v)\", \"Y7\", False),\n",
    "    (\"if i = 5, Y7(t_v)\", \"Y7\", False),\n",
    "    (\"if i = 6, Y7(t_v)\", \"Y7\", False),\n",
    "    (\"if i = 1, I(8 ≤ r_i)Y7(t_v)\", \"Y7\", True),\n",
    "    (\"if 2 ≤ i ≤ 4, I(8 ≤ r_i)Y7(t_v)\", \"Y7\", True),\n",
    "    (\"if i = 5, I(8 ≤ r_i)Y7(t_v)\", \"Y7\", True),\n",
    "    (\"if i = 6, I(8 ≤ r_i)Y7(t_v)\", \"Y7\", True),\n",
    "]\n",
    "I5_specs = [\n",
    "    (\"if 1 ≤ i ≤ 4, Y5(t_v)\", \"Y5\", False),\n",
    "    (\"if i = 5, Y5(t_v)\", \"Y5\", False),\n",
    "    (\"if i = 6, Y5(t_v)\", \"Y5\", False),\n",
    "    (\"if i = 1, I(8 ≤ r_i)Y5(t_v)\", \"Y5\", True),\n",
    "    (\"if 2 ≤ i ≤ 4, I(8 ≤ r_i)Y5(t_v)\", \"Y5\", True),\n",
    "    (\"if i = 5, I(8 ≤ r_i)Y5(t_v)\", \"Y5\", True),\n",
    "    (\"if i = 6, I(8 ≤ r_i)Y5(t_v)\", \"Y5\", True),\n",
    "    (\"if i = 7, Y5(t_v)\", \"Y5\", False),  # explicitly shown as missing row in image\n",
    "]\n",
    "Y9_specs = [\n",
    "    (\"i = 1 or 2, Y9(t_v)\", \"Y9\", False),\n",
    "    (\"i = 1 or 2, I(8 ≤ r_i)Y9(t_v)\", \"Y9\", True),\n",
    "]\n",
    "Y10_specs = [\n",
    "    (\"1 ≤ i ≤ 3, Y10(t_v)\", \"Y10\", False),\n",
    "    (\"i = 4, Y10(t_v)\", \"Y10\", False),\n",
    "    (\"i = 5, Y10(t_v)\", \"Y10\", False),\n",
    "    (\"i = 6, Y10(t_v)\", \"Y10\", False),\n",
    "]\n",
    "\n",
    "write_I(I1_specs, \"I1\")\n",
    "write_I(I2_specs, \"I2\")\n",
    "write_I(I3_specs, \"I3\")\n",
    "write_I(I4_specs, \"I4\")\n",
    "write_I(I5_specs, \"I5\")\n",
    "write_I(Y9_specs, \"Y9_block\")\n",
    "write_I(Y10_specs, \"Y10_block\")\n",
    "\n",
    "# --------------------------- DONE ---------------------------\n",
    "print(\"✓ OR mini-tables     ->\", OR_PROB_DIR / \"OR_summary.csv\")\n",
    "print(\"✓ Imputed draws      ->\", OR_DRAW_DIR / \"all_draws.csv\", f\"(rows={len(all_draws)})\")\n",
    "print(\"✓ I*-tables (CSVs)   ->\", I_DIR)\n",
    "print(\"Notes:\")\n",
    "print(\" - If OR blocks are empty, check that 'Sum breakdown' entries numerically contain MI bins in table4.\")\n",
    "print(\" - Add 'yk_patterns.csv' and/or 'mask_by_tv.csv' to control Y_k(t_v) and I(8 ≤ r_i).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62bf0fbe-b6a9-459f-83dc-3c342bca66bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('if 1 ≤ i ≤ 4, Y1(t_v)', 'Y1', False),\n",
       " ('if i = 1, I(8 ≤ r_i)Y1(t_v)', 'Y1', True),\n",
       " ('if 2 ≤ i ≤ 4, I(8 ≤ r_i)Y1(t_v)', 'Y1', True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I1_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d4a87-85f8-4f0f-b6eb-43d56ac737f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
