{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afdcc918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     s       tau   std_dev  z_statistic   p_value  avg_subsample_size\n",
      "0    9  0.162481  0.649494     0.250165  0.802459            3.825254\n",
      "1   10  0.216063  0.469287     0.460408  0.645224            5.548519\n",
      "2   11  0.148926  0.212636     0.700378  0.483692           11.565000\n",
      "3   12  0.067389  0.176733     0.381302  0.702979           12.851000\n",
      "4   13  0.095988  0.128833     0.745057  0.456238           16.692000\n",
      "5   14  0.015427  0.134395     0.114788  0.908613           18.277000\n",
      "6   15  0.054019  0.117559     0.459502  0.645874           21.614000\n",
      "7   16  0.029078  0.106984     0.271795  0.785780           22.101000\n",
      "8   17  0.005975  0.098520     0.060647  0.951640           21.659000\n",
      "9   18 -0.002833  0.093364    -0.030342  0.975795           20.082000\n",
      "10  19 -0.024394  0.085391    -0.285679  0.775124           19.729000\n",
      "11  20 -0.014461  0.084845    -0.170438  0.864665           19.275000\n",
      "12  21  0.006429  0.080824     0.079539  0.936604           18.742000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "def load_mi_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data[['l', 'r', 'w', 'z', 'p']]\n",
    "\n",
    "def impute_rectangles(mi_rectangles, probabilities, num_imputations):\n",
    "    return mi_rectangles[np.random.choice(len(mi_rectangles), \n",
    "                                          size=num_imputations, \n",
    "                                          p=probabilities)]\n",
    "\n",
    "def is_concordant(rect1, rect2):\n",
    "    if (rect1[1] < rect2[0] and rect1[3] < rect2[2]) or \\\n",
    "       (rect2[1] < rect1[0] and rect2[3] < rect1[2]):\n",
    "        return 1\n",
    "    elif (rect1[1] < rect2[0] and rect1[2] > rect2[3]) or \\\n",
    "         (rect2[1] < rect1[0] and rect2[2] > rect1[3]):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def kendall_tau_for_imputation(imputed_rectangles, t):\n",
    "    n = len(imputed_rectangles)\n",
    "    concordant_pairs = 0\n",
    "    total_pairs = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if imputed_rectangles[i][1] <= t < imputed_rectangles[i][3] and \\\n",
    "               imputed_rectangles[j][1] <= t < imputed_rectangles[j][3]:\n",
    "                concordant_pairs += is_concordant(imputed_rectangles[i], imputed_rectangles[j])\n",
    "                total_pairs += 1\n",
    "    \n",
    "    if total_pairs == 0:\n",
    "        return 0\n",
    "    \n",
    "    return concordant_pairs / total_pairs\n",
    "\n",
    "def test_markov_property(mi_data, s_values, num_imputations=1000):\n",
    "    mi_rectangles = mi_data[['l', 'r', 'w', 'z']].values\n",
    "    probabilities = mi_data['p'].values\n",
    "    \n",
    "    results = []\n",
    "    for s in s_values:\n",
    "        tau_values = []\n",
    "        subsample_sizes = []\n",
    "        \n",
    "        for _ in range(num_imputations):\n",
    "            imputed_data = impute_rectangles(mi_rectangles, probabilities, len(mi_rectangles))\n",
    "            relevant_data = imputed_data[(imputed_data[:, 1] <= s) & (s < imputed_data[:, 3])]\n",
    "            \n",
    "            if len(relevant_data) > 1:\n",
    "                tau = kendall_tau_for_imputation(relevant_data, s)\n",
    "                tau_values.append(tau)\n",
    "                subsample_sizes.append(len(relevant_data))\n",
    "        \n",
    "        if tau_values:\n",
    "            tau_mean = np.mean(tau_values)\n",
    "            tau_variance = np.var(tau_values, ddof=1)\n",
    "            \n",
    "            # Compute the variance as in equation (11)\n",
    "            within_imputation_var = np.mean([2/((n*(n-1))) for n in subsample_sizes])\n",
    "            between_imputation_var = (1 + 1/num_imputations) * tau_variance\n",
    "            total_variance = within_imputation_var + between_imputation_var\n",
    "            \n",
    "            z_statistic = tau_mean / np.sqrt(total_variance)\n",
    "            p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))\n",
    "            \n",
    "            results.append({\n",
    "                's': s,\n",
    "                'tau': tau_mean,\n",
    "                'std_dev': np.sqrt(total_variance),\n",
    "                'z_statistic': z_statistic,\n",
    "                'p_value': p_value,\n",
    "                'avg_subsample_size': np.mean(subsample_sizes)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    mi_data = load_mi_data('MI.csv')\n",
    "    s_values = range(9, 22)  # As in Table 3\n",
    "    results = test_markov_property(mi_data, s_values)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab4e20-1f95-4d94-8f2b-c4cf1e85aa86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
