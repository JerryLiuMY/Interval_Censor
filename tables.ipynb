{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b5ca463-6198-47fe-9e07-01a78aec7847",
   "metadata": {},
   "source": [
    "## Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e27f2b0-63e5-4465-b005-93530010f32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " t_v  ∑ dN_i(t_v)  ∑ ​I(8 ≤ r_i) dN_i(t_v)  ∑ Y_i(t_v)  ∑ ​I(8 ≤ r_i) Y_i(t_v)\n",
      "  12            2                        0          16                      10\n",
      "  13            2                        0          17                      13\n",
      "  15            3                        3          22                      20\n",
      "  16            4                        3          20                      18\n",
      "  17            2                        1          16                      15\n",
      "  18            6                        6          14                      14\n",
      "  19            1                        1           8                       8\n",
      "  20            2                        2           7                       7\n",
      "  21            2                        2           5                       5\n",
      "  22            1                        1           3                       3\n",
      "  23            2                        2           2                       2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "###############################################################################\n",
    "# 0)  CONFIG\n",
    "###############################################################################\n",
    "S_FOCAL = 8                     # “s = 8” in the paper\n",
    "REDUCED_FILE = \"proper_OR.csv\"    # path to the proper‑OR file you generated\n",
    "\n",
    "###############################################################################\n",
    "# 1)  READ  &  PARSE  (r , z)\n",
    "###############################################################################\n",
    "df = pd.read_csv(REDUCED_FILE)\n",
    "\n",
    "# the third column looks like \"(7, 12)\" → split it into integers\n",
    "def parse_pair(txt):\n",
    "    r, z = map(int, re.findall(r\"\\d+\", txt))\n",
    "    return pd.Series({\"r\": r, \"z\": z})\n",
    "\n",
    "df[[\"r\", \"z\"]] = df.iloc[:, 2].apply(parse_pair)\n",
    "\n",
    "###############################################################################\n",
    "# 2)  BUILD THE TABLE\n",
    "###############################################################################\n",
    "records = []\n",
    "for t_v in sorted(df[\"z\"].unique()):          # 11 unique 2→3 times\n",
    "    # Number of 2→3 events at t_v\n",
    "    dN = (df[\"z\"] == t_v).sum()\n",
    "\n",
    "    # … among those who were still in state 1 at s = 8  (⇔  r_i ≥ 8)\n",
    "    dN_s8 = ((df[\"z\"] == t_v) & (df[\"r\"] >= S_FOCAL)).sum()\n",
    "\n",
    "    # Risk set just before t_v:  r_i < t_v  &  z_i ≥ t_v\n",
    "    at_risk = (df[\"r\"] < t_v) & (df[\"z\"] >= t_v)\n",
    "    Y  = at_risk.sum()\n",
    "\n",
    "    # … and who were in state 1 at s = 8\n",
    "    Y_s8 = (at_risk & (df[\"r\"] >= S_FOCAL)).sum()\n",
    "\n",
    "    records.append((t_v, dN, dN_s8, Y, Y_s8))\n",
    "\n",
    "table3 = pd.DataFrame(\n",
    "    records,\n",
    "    columns=[\n",
    "        \"t_v\",\n",
    "        r\"∑ dN_i(t_v)\",\n",
    "        r\"∑ ​I(8 ≤ r_i) dN_i(t_v)\",\n",
    "        r\"∑ Y_i(t_v)\",\n",
    "        r\"∑ ​I(8 ≤ r_i) Y_i(t_v)\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# 3)  DISPLAY\n",
    "###############################################################################\n",
    "print(table3.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66327d3c-7625-4db7-8fda-78cc89a1d701",
   "metadata": {},
   "source": [
    "## Table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90eeff4d-01ec-4514-9ee3-d15e03ebab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improper OR=Improper MI  multiplicity  reduced       p\n",
      "        (9,10) × (23,∞)             2 (10, 23)  0.0639\n",
      "       (10,11) × (23,∞)             7 (11, 23)  0.1649\n",
      "       (11,12) × (23,∞)             1 (12, 23)  0.0379\n",
      "       (12,13) × (23,∞)             7 (13, 23)  0.1682\n",
      "       (14,15) × (23,∞)             8 (15, 23)  0.1548\n",
      "       (15,16) × (23,∞)             5 (16, 23)  0.0619\n",
      "                  total            30                 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load CSV files\n",
    "improper_or_df = pd.read_csv(\"improper_OR.csv\")\n",
    "improper_mi_df = pd.read_csv(\"improper_MI.csv\")\n",
    "\n",
    "# Extract r from Reduced (r, 23) column\n",
    "reduced_rows = improper_mi_df[\"Reduced (r,23)\"].str.extract(r\"\\((\\d+),\\s*23\\)\").astype(int)\n",
    "improper_mi_df[\"r\"] = reduced_rows[0]\n",
    "\n",
    "# Count multiplicities from improper_OR: match (L, L+1] x (23, ∞)\n",
    "counts = defaultdict(int)\n",
    "for _, row in improper_or_df.iterrows():\n",
    "    L, R, W = row['L'], row['R'], row['W']\n",
    "    if W == 23 and R == L + 1:\n",
    "        counts[R] += 1  # R is r in (r, 23)\n",
    "\n",
    "# Filter MI rows with matching r and create table format\n",
    "table5_df = improper_mi_df[improper_mi_df[\"r\"].isin(counts.keys())].copy()\n",
    "table5_df[\"multiplicity\"] = table5_df[\"r\"].map(counts)\n",
    "table5_df[\"Improper OR=Improper MI\"] = table5_df[\"r\"].apply(lambda r: f\"({r-1},{r}) × (23,∞)\")\n",
    "table5_df[\"reduced\"] = table5_df[\"r\"].apply(lambda r: f\"({r}, 23)\")\n",
    "\n",
    "# Final table with desired columns\n",
    "table5 = table5_df[[\"Improper OR=Improper MI\", \"multiplicity\", \"reduced\", \"p\"]].copy()\n",
    "\n",
    "# Optional: add total row\n",
    "total_multiplicity = table5[\"multiplicity\"].sum()\n",
    "table5.loc[\"total\"] = [\"total\", total_multiplicity, \"\", \"\"]\n",
    "\n",
    "# Print the table\n",
    "print(table5.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c85c0-a740-4859-80bb-e1035e2ae235",
   "metadata": {},
   "source": [
    "## Table 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1ce895-0e0a-497a-82c7-6b7f567a3608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Improper OR       Improper MI  multiplicity reduced (r,23)\n",
      "  (1,7) × (23,∞)   (5,7] × (23, ∞)             1         (7,23)\n",
      "  (5,7) × (23,∞)   (5,7] × (23, ∞)             2         (7,23)\n",
      "  (7,9) × (23,∞)   (8,9] × (23, ∞)             1         (9,23)\n",
      "(12,14) × (23,∞) (12,13] × (23, ∞)             2        (13,23)\n",
      "(13,15) × (23,∞) (14,15] × (23, ∞)             3        (15,23)\n",
      "           total                               9               \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Load ---\n",
    "or_df = pd.read_csv(\"improper_OR.csv\")      # columns: L, R, W, Z\n",
    "mi_df = pd.read_csv(\"improper_MI.csv\")      # columns: Improper MI, p, Reduced (r,23)\n",
    "\n",
    "# --- Parse MI endpoints from strings like \"(5,7] × (23, ∞)\" ---\n",
    "uv = mi_df[\"Improper MI\"].str.extract(r\"\\((\\d+)\\s*,\\s*(\\d+)\\]\")\n",
    "mi_df[\"u\"] = uv[0].astype(int)\n",
    "mi_df[\"v\"] = uv[1].astype(int)\n",
    "mi_keep = mi_df[[\"u\", \"v\", \"Improper MI\", \"Reduced (r,23)\"]].copy()\n",
    "\n",
    "# --- Candidate improper ORs: W==23 (improper); we’ll later split adjacent vs non-adjacent ---\n",
    "cand_or = or_df[or_df[\"W\"] == 23][[\"L\", \"R\"]].drop_duplicates()\n",
    "\n",
    "# --- Containment: Type 1 = contains exactly one improper MI ---\n",
    "cross = cand_or.merge(mi_keep, how=\"cross\")\n",
    "contained = cross[(cross[\"L\"] <= cross[\"u\"]) & (cross[\"v\"] <= cross[\"R\"])]\n",
    "\n",
    "# Count # of improper MIs each OR contains\n",
    "mi_counts = contained.groupby([\"L\", \"R\"]).size().reset_index(name=\"num_improper_MI\")\n",
    "\n",
    "# Keep only Type-1 ORs (exactly one improper MI)\n",
    "type1_or = mi_counts[mi_counts[\"num_improper_MI\"] == 1][[\"L\", \"R\"]]\n",
    "\n",
    "# --- Table 6 subset: NOT of the form (L, L+1) ---\n",
    "table6_or = type1_or[type1_or[\"R\"] != type1_or[\"L\"] + 1]\n",
    "\n",
    "# Attach the unique MI row for each selected OR\n",
    "one_mi_detail = table6_or.merge(contained, on=[\"L\", \"R\"], how=\"left\")\n",
    "\n",
    "# Multiplicity of each OR in raw data (how many times it appears with W=23)\n",
    "mult = (or_df[or_df[\"W\"] == 23]\n",
    "        .groupby([\"L\", \"R\"]).size().reset_index(name=\"multiplicity\"))\n",
    "\n",
    "# Build Table 6\n",
    "final = (one_mi_detail.merge(mult, on=[\"L\", \"R\"], how=\"left\")\n",
    "         .drop_duplicates(subset=[\"L\",\"R\"])            # exactly one MI per OR\n",
    "         .sort_values(by=[\"R\", \"L\"])\n",
    "         .assign(\n",
    "             **{\n",
    "                 \"Improper OR\":    lambda d: d.apply(lambda r: f\"({r.L},{r.R}) × (23,∞)\", axis=1),\n",
    "                 \"reduced (r,23)\": lambda d: d[\"Reduced (r,23)\"],\n",
    "             }\n",
    "         )[[\"Improper OR\", \"Improper MI\", \"multiplicity\", \"reduced (r,23)\"]]\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "# Add total row — multiplicities should sum to 9\n",
    "table6 = pd.concat(\n",
    "    [final, pd.DataFrame([[\"total\", \"\", final[\"multiplicity\"].sum(), \"\"]], columns=final.columns)],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "print(table6.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a8411-abfe-4f02-beb6-4119c8a8d7a2",
   "metadata": {},
   "source": [
    "## Table 6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b17613-3179-4556-ae5b-2cc137730db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " t_v  ∑ dN_i(t_v)  ∑ I(8 ≤ r_i) dN_i(t_v)   ∑ Y_i(t_v) ∑ I(8 ≤ r_i) Y_i(t_v)\n",
      "  12            2                       0 16 + 13 = 29          10 + 10 = 20\n",
      "  13            2                       0 17 + 14 = 31          13 + 11 = 24\n",
      "  15            3                       3 22 + 23 = 45          20 + 20 = 40\n",
      "  16            4                       3 20 + 34 = 54          18 + 31 = 49\n",
      "  17            2                       1 16 + 39 = 55          15 + 36 = 51\n",
      "  18            6                       6 14 + 39 = 53          14 + 36 = 50\n",
      "  19            1                       1  8 + 39 = 47           8 + 36 = 44\n",
      "  20            2                       2  7 + 39 = 46           7 + 36 = 43\n",
      "  21            2                       2  5 + 39 = 44           5 + 36 = 41\n",
      "  22            1                       1  3 + 39 = 42           3 + 36 = 39\n",
      "  23            2                       2  2 + 39 = 41           2 + 36 = 38\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------\n",
    "# 1) Load inputs\n",
    "# -------------------------\n",
    "table3 = pd.read_csv(\"table3.csv\")\n",
    "table5 = pd.read_csv(\"table5.csv\")\n",
    "table6 = pd.read_csv(\"table6.csv\")\n",
    "\n",
    "# -------------------------\n",
    "# 2) Helpers\n",
    "# -------------------------\n",
    "def find_col(df, substrings):\n",
    "    \"\"\"Return the first column whose name contains ALL substrings (case-insensitive).\"\"\"\n",
    "    subs = [s.lower() for s in substrings]\n",
    "    for c in df.columns:\n",
    "        cl = c.lower()\n",
    "        if all(s in cl for s in subs):\n",
    "            return c\n",
    "    raise KeyError(f\"Column with substrings {substrings} not found in {list(df.columns)}\")\n",
    "\n",
    "def extract_r(val):\n",
    "    \"\"\"Extract integer r from '(r,23)' allowing spaces.\"\"\"\n",
    "    if not isinstance(val, str):\n",
    "        return None\n",
    "    m = re.search(r\"\\((\\d+)\\s*,\\s*23\\)\", val)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# -------------------------\n",
    "# 3) Parse reduced points & multiplicities from Tables 5 & 6\n",
    "# -------------------------\n",
    "col_mult_5 = find_col(table5, [\"multiplicity\"])\n",
    "col_red_5  = find_col(table5, [\"reduced\"])            # e.g., \"reduced\"\n",
    "r_mult_5 = (\n",
    "    table5.assign(r=table5[col_red_5].apply(extract_r))\n",
    "          .dropna(subset=[\"r\"])\n",
    "          [[\"r\", col_mult_5]]\n",
    "          .rename(columns={col_mult_5: \"multiplicity\"})\n",
    ")\n",
    "\n",
    "col_mult_6 = find_col(table6, [\"multiplicity\"])\n",
    "col_red_6  = find_col(table6, [\"reduced\"])            # e.g., \"reduced (r,23)\"\n",
    "r_mult_6 = (\n",
    "    table6.assign(r=table6[col_red_6].apply(extract_r))\n",
    "          .dropna(subset=[\"r\"])\n",
    "          [[\"r\", col_mult_6]]\n",
    "          .rename(columns={col_mult_6: \"multiplicity\"})\n",
    ")\n",
    "\n",
    "# Combine 5 & 6, then aggregate multiplicities per r\n",
    "r_mult = (\n",
    "    pd.concat([r_mult_5, r_mult_6], ignore_index=True)\n",
    "      .groupby(\"r\", as_index=False)[\"multiplicity\"].sum()\n",
    "      .sort_values(\"r\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Precompute cumulative sums over r for fast lookups of r < t_v\n",
    "r_mult[\"cum_all\"]  = r_mult[\"multiplicity\"].cumsum()\n",
    "r_mult[\"ge8\"]      = (r_mult[\"r\"] >= 8).astype(int) * r_mult[\"multiplicity\"]\n",
    "r_mult[\"cum_ge8\"]  = r_mult[\"ge8\"].cumsum()\n",
    "\n",
    "def cum_less_than(tv, colname):\n",
    "    \"\"\"Cumulative sum of selected multiplicities for all r < tv.\"\"\"\n",
    "    eligible = r_mult[r_mult[\"r\"] < tv]\n",
    "    return int(eligible[colname].iloc[-1]) if not eligible.empty else 0\n",
    "\n",
    "# -------------------------\n",
    "# 4) Read needed columns from Table 3 and build Table 6a\n",
    "# -------------------------\n",
    "col_tv      = find_col(table3, [\"t_v\"])\n",
    "col_dN      = find_col(table3, [\"∑\", \"dn\"])              # \"∑ dN_i(t_v)\"\n",
    "col_I8dN    = find_col(table3, [\"∑\", \"i(8\", \"dn\"])       # \"∑ I(8 ≤ r_i) dN_i(t_v)\"\n",
    "col_Y       = find_col(table3, [\"∑\", \"y_i\"])             # \"∑ Y_i(t_v)\"\n",
    "col_I8Y     = find_col(table3, [\"∑\", \"i(8\", \"y_i\"])      # \"∑ I(8 ≤ r_i) Y_i(t_v)\"\n",
    "\n",
    "rows = []\n",
    "for _, r in table3.iterrows():\n",
    "    tv    = int(r[col_tv])\n",
    "    dN    = int(r[col_dN])\n",
    "    I8dN  = int(r[col_I8dN])\n",
    "    Y0    = int(r[col_Y])\n",
    "    I8Y0  = int(r[col_I8Y])\n",
    "\n",
    "    add_Y   = cum_less_than(tv, \"cum_all\")   # all r<tv\n",
    "    add_I8Y = cum_less_than(tv, \"cum_ge8\")   # only r>=8, r<tv\n",
    "\n",
    "    rows.append({\n",
    "        \"t_v\": tv,\n",
    "        \"∑ dN_i(t_v)\": dN,\n",
    "        \"∑ I(8 ≤ r_i) dN_i(t_v)\": I8dN,\n",
    "        \"∑ Y_i(t_v)\": f\"{Y0} + {add_Y} = {Y0 + add_Y}\",\n",
    "        \"∑ I(8 ≤ r_i) Y_i(t_v)\": f\"{I8Y0} + {add_I8Y} = {I8Y0 + add_I8Y}\",\n",
    "    })\n",
    "\n",
    "table6a = pd.DataFrame(rows)\n",
    "\n",
    "# -------------------------\n",
    "# 5) Save result\n",
    "# -------------------------\n",
    "table6a.to_csv(\"table6a.csv\", index=False)\n",
    "print(table6a.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72181c34-a7fc-4621-a229-cf569e6e7783",
   "metadata": {},
   "source": [
    "## Test Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14985ff2-90b7-48ff-a038-4ff86fb628ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    t_v  sum_dN  sum_I_dN  sum_Y  sum_I_Y       U_t\n",
      "0    12     2.0       0.0   29.0     20.0 -1.379310\n",
      "1    13     2.0       0.0   31.0     24.0 -1.548387\n",
      "2    15     3.0       3.0   45.0     40.0  0.333333\n",
      "3    16     4.0       3.0   54.0     49.0 -0.629630\n",
      "4    17     2.0       1.0   55.0     51.0 -0.854545\n",
      "5    18     6.0       6.0   53.0     50.0  0.339623\n",
      "6    19     1.0       1.0   47.0     44.0  0.063830\n",
      "7    20     2.0       2.0   46.0     43.0  0.130435\n",
      "8    21     2.0       2.0   44.0     41.0  0.136364\n",
      "9    22     1.0       1.0   42.0     39.0  0.071429\n",
      "10   23     2.0       2.0   41.0     38.0  0.146341\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- Load & normalize columns ---\n",
    "df = pd.read_csv(\"table6a.csv\").rename(columns={\n",
    "    't_v': 't_v',\n",
    "    '∑ dN_i(t_v)': 'sum_dN',\n",
    "    '∑ I(8 ≤ r_i) dN_i(t_v)': 'sum_I_dN',\n",
    "    '∑ Y_i(t_v)': 'sum_Y',\n",
    "    '∑ I(8 ≤ r_i) Y_i(t_v)': 'sum_I_Y'\n",
    "})\n",
    "\n",
    "def to_number(x):\n",
    "    \"\"\"Extract the numeric total from entries like '16 + 13 = 29' or pass through numbers.\"\"\"\n",
    "    if pd.isna(x): \n",
    "        return pd.NA\n",
    "    if isinstance(x, (int, float)): \n",
    "        return x\n",
    "    s = str(x)\n",
    "    nums = re.findall(r'(-?\\d+(?:\\.\\d+)?)', s)\n",
    "    return float(nums[-1]) if nums else pd.NA\n",
    "\n",
    "for c in ['sum_dN', 'sum_I_dN', 'sum_Y', 'sum_I_Y']:\n",
    "    df[c] = df[c].apply(to_number).astype(float)\n",
    "\n",
    "# --- Compute U(t_v) ---\n",
    "# U(t_v) = sum_I_dN - sum_I_Y * (sum_dN / sum_Y)\n",
    "df['U_t'] = df['sum_I_dN'] - df['sum_I_Y'] * (df['sum_dN'] / df['sum_Y'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b85787b9-893f-4113-b1ed-62eaed5d79cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistics: -3.1905\n"
     ]
    }
   ],
   "source": [
    "# --- Compute total U ---\n",
    "U = df['U_t'].sum()\n",
    "print(f\"Test Statistics: {round(U, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeea73dc-daa3-41ef-89a8-5e08760f0095",
   "metadata": {},
   "source": [
    "## Table 6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7341b45-ac86-4485-a454-c505afa82d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 6b saved to table6b.csv\n",
      "    t_v  n_V  n_{v1}  n_{v1}(n_V - n_{v1})/n_V^2\n",
      "0    12   29      20                    0.214031\n",
      "1    13   31      24                    0.174818\n",
      "2    15   45      40                    0.098765\n",
      "3    16   54      49                    0.084019\n",
      "4    17   55      51                    0.067438\n",
      "5    18   53      50                    0.053400\n",
      "6    19   47      44                    0.059756\n",
      "7    20   46      43                    0.060964\n",
      "8    21   44      41                    0.063533\n",
      "9    22   42      39                    0.066327\n",
      "10   23   41      38                    0.067817\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === Load the input table (Table 6a stats) ===\n",
    "df = pd.read_csv(\"table6a_stats.csv\")\n",
    "\n",
    "# Extract relevant columns\n",
    "tv = df[\"t_v\"].astype(int)         # time values\n",
    "nV = df[\"sum_Y\"].astype(int)       # n_V = sum of Y_i(t_v)\n",
    "nv1 = df[\"sum_I_Y\"].astype(int)    # n_{v1} = sum of I(8 <= r_i) Y_i(t_v)\n",
    "\n",
    "# Compute the formula: n_{v1}(n_V - n_{v1}) / n_V^2\n",
    "value = nv1 * (nV - nv1) / (nV ** 2)\n",
    "\n",
    "# Build Table 6b DataFrame\n",
    "table6b = pd.DataFrame({\n",
    "    \"t_v\": tv,\n",
    "    \"n_V\": nV,\n",
    "    \"n_{v1}\": nv1,\n",
    "    \"n_{v1}(n_V - n_{v1})/n_V^2\": value.round(6)\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "table6b.to_csv(\"table6b.csv\", index=False)\n",
    "\n",
    "print(\"Table 6b saved to table6b.csv\")\n",
    "print(table6b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d612dd7-6b7d-4ac7-8211-de9e0f08d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Test Statistics: -3.1733\n"
     ]
    }
   ],
   "source": [
    "# --- Compute standardized test statistic ---\n",
    "df[\"var_term\"] = df.apply(lambda row: (row[\"sum_I_Y\"] * (row[\"sum_Y\"] - row[\"sum_I_Y\"])) / (row[\"sum_Y\"]**2) if row[\"sum_Y\"] > 0 else 0, axis=1)\n",
    "V_U = df[\"var_term\"].sum()\n",
    "\n",
    "U_std = U / np.sqrt(V_U) if V_U > 0 else np.nan\n",
    "\n",
    "print(f\"Standardized Test Statistics: {round(U_std, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b48e9c-6280-4bb6-a1e9-d2969cf51ab5",
   "metadata": {},
   "source": [
    "## Table 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ba828c6-55ca-4baf-97cb-af785b255ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 7 (type 2 improper ORs) saved to table7.csv\n",
      "Imp OR (L,R]  multiplicity  Total probability (numeric)                                                                  Sum breakdown\n",
      "     (1, 11]             1                       0.2960                                      0.0437 + 0.0235 + 0.0639 + 0.1649 = 0.296\n",
      "     (1, 12]             2                       0.3339                            0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 = 0.3339\n",
      "     (1, 13]             2                       0.5021                   0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 = 0.5021\n",
      "     (1, 14]             3                       0.5021                   0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 = 0.5021\n",
      "     (1, 15]             2                       0.6569          0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 + 0.1548 = 0.6569\n",
      "     (1, 16]             1                       0.7188 0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 + 0.1548 + 0.0619 = 0.7188\n",
      "     (3, 14]             1                       0.5021                   0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 = 0.5021\n",
      "     (3, 15]             1                       0.6569          0.0437 + 0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 + 0.1548 = 0.6569\n",
      "     (7, 10]             1                       0.0874                                                       0.0235 + 0.0639 = 0.0874\n",
      "     (7, 15]             1                       0.6132                   0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 + 0.1548 = 0.6132\n",
      "     (8, 10]             1                       0.0874                                                       0.0235 + 0.0639 = 0.0874\n",
      "     (8, 15]             1                       0.6132                   0.0235 + 0.0639 + 0.1649 + 0.0379 + 0.1682 + 0.1548 = 0.6132\n",
      "     (9, 12]             3                       0.2667                                              0.0639 + 0.1649 + 0.0379 = 0.2667\n",
      "    (10, 12]             2                       0.2028                                                       0.1649 + 0.0379 = 0.2028\n",
      "    (10, 15]             1                       0.5258                                     0.1649 + 0.0379 + 0.1682 + 0.1548 = 0.5258\n",
      "    (11, 13]             4                       0.2061                                                       0.0379 + 0.1682 = 0.2061\n",
      "    (13, 16]             1                       0.2167                                                       0.1548 + 0.0619 = 0.2167\n",
      "    (14, 16]             2                       0.2167                                                       0.1548 + 0.0619 = 0.2167\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure Pandas prints full strings without truncation\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# === 1) Load inputs ===\n",
    "improper_or = pd.read_csv(\"improper_OR.csv\")\n",
    "table4 = pd.read_csv(\"table4.csv\")\n",
    "\n",
    "# Clean headers\n",
    "improper_or.columns = [c.strip() for c in improper_or.columns]\n",
    "table4.columns = [c.strip() for c in table4.columns]\n",
    "\n",
    "# === 2) Parse r from Reduced column and convert p ===\n",
    "def extract_r(cell: str) -> int:\n",
    "    m = re.search(r\"\\(\\s*(\\d+)\\s*,\\s*23\\s*\\)\", str(cell))\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse Reduced (r,23): {cell}\")\n",
    "    return int(m.group(1))\n",
    "\n",
    "table4[\"_r\"] = table4[\"Reduced (r,23)\"].apply(extract_r)\n",
    "table4[\"_p\"] = pd.to_numeric(table4[\"p\"], errors=\"coerce\")\n",
    "r_to_p = table4[[\"_r\", \"_p\"]]\n",
    "\n",
    "# === 3) Collapse improper_OR into unique (L,R] with multiplicity ===\n",
    "improper_or[\"L\"] = improper_or[\"L\"].astype(int)\n",
    "improper_or[\"R\"] = improper_or[\"R\"].astype(int)\n",
    "\n",
    "grouped = (\n",
    "    improper_or.groupby([\"L\", \"R\"], as_index=False)\n",
    "    .size()\n",
    "    .rename(columns={\"size\": \"multiplicity\"})\n",
    "    .sort_values([\"L\", \"R\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# === 4) Compute probability sums ===\n",
    "def sum_for_interval(L: int, R: int):\n",
    "    mask = (r_to_p[\"_r\"] > L) & (r_to_p[\"_r\"] <= R)\n",
    "    probs = r_to_p.loc[mask, \"_p\"].dropna().tolist()\n",
    "    total = float(sum(probs))\n",
    "    terms = \" + \".join(f\"{p:.4f}\".rstrip(\"0\").rstrip(\".\") for p in probs)\n",
    "    expr = f\"{terms} = {total:.4f}\".rstrip(\"0\").rstrip(\".\") if terms else \"0 = 0\"\n",
    "    return total, expr, len(probs)\n",
    "\n",
    "totals, exprs, counts = [], [], []\n",
    "for _, row in grouped.iterrows():\n",
    "    total, expr, count = sum_for_interval(int(row[\"L\"]), int(row[\"R\"]))\n",
    "    totals.append(total)\n",
    "    exprs.append(expr)\n",
    "    counts.append(count)\n",
    "\n",
    "grouped[\"Total probability (numeric)\"] = totals\n",
    "grouped[\"Sum breakdown\"] = exprs\n",
    "grouped[\"num_MI_rects\"] = counts\n",
    "\n",
    "# === 5) Keep only type 2 ORs (more than one MI rectangle) ===\n",
    "table7 = grouped[grouped[\"num_MI_rects\"] > 1].copy()\n",
    "\n",
    "# Nicely formatted interval column\n",
    "table7.insert(0, \"Imp OR (L,R]\", table7.apply(lambda r: f\"({int(r['L'])}, {int(r['R'])}]\", axis=1))\n",
    "\n",
    "# Drop helper columns and reset index\n",
    "table7 = table7.drop(columns=[\"L\", \"R\", \"num_MI_rects\"]).reset_index(drop=True)\n",
    "\n",
    "# === 6) Save to CSV ===\n",
    "table7.to_csv(\"table7.csv\", index=False)\n",
    "\n",
    "print(\"Table 7 (type 2 improper ORs) saved to table7.csv\")\n",
    "print(table7.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301dba40-a1fb-44df-b0a3-b0afa4e90dad",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "588cb371-95a9-430b-940f-d32c34fa43b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote normalized probabilities and 0/1 tables to: /Users/mingyu/Desktop/PhD/Thesis/Interval_Censor/out_or_tables\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Generate normalized probabilities and 0/1 step tables from Table 7.\n",
    "\n",
    "Inputs\n",
    "------\n",
    "- table7.csv with columns:\n",
    "  ['Imp OR (L,R]', 'multiplicity', 'Total probability (numeric)', 'Sum breakdown']\n",
    "  where 'Sum breakdown' looks like '0.0437 + 0.0235 + ... = 0.296'\n",
    "\n",
    "Outputs (default: ./out_or_tables/)\n",
    "-------\n",
    "- normalized_probs_all.csv\n",
    "- table_<OR>_01.csv for each OR listed in tables_spec\n",
    "\n",
    "Notes\n",
    "-----\n",
    "- Update `tables_spec` below if you want to tweak any 0/1 thresholds.\n",
    "- Update `tv_cols` if your column set differs from 12..23.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "TABLE7_PATH = \"table7.csv\"                  # change to your path if needed\n",
    "OUT_DIR = Path(\"./out_or_tables\")           # where to write CSVs\n",
    "tv_cols = list(range(12, 24))               # columns 12..23 inclusive (as in the images)\n",
    "\n",
    "# --- 0/1 step table specs ---\n",
    "# Each entry is a list of (row_label, start_tv) pairs.\n",
    "# Row is 1 for tv >= start_tv, 0 before. Use start_tv=None for all-zeros rows.\n",
    "tables_spec: Dict[str, List[Tuple[str, int | None]]] = {\n",
    "    # OR1 = (1, 11]\n",
    "    \"(1, 11]\": [\n",
    "        (\"if 1 ≤ i ≤ 4, Y1(tv)\", 12),\n",
    "        (\"if i = 1, I(8 ≤ 7)Y1(tv)\", None),      # indicator false → all zeros\n",
    "        (\"if 2 ≤ i ≤ 4, I(8 ≤ r_i)Y1(tv)\", 12),\n",
    "    ],\n",
    "    # OR2 = (1, 12]\n",
    "    \"(1, 12]\": [\n",
    "        (\"if 1 ≤ i ≤ 4, Y2(tv)\", 12),\n",
    "        (\"if i = 5, Y2(tv)\", 13),\n",
    "        (\"if i = 1, I(8 ≤ 7)Y2(tv)\", None),\n",
    "        (\"if 2 ≤ i ≤ 4, I(8 ≤ r_i)Y2(tv)\", 12),\n",
    "        (\"if i = 5, I(8 ≤ r5)Y2(tv)\", 13),\n",
    "    ],\n",
    "    # OR3 = (1, 13]\n",
    "    \"(1, 13]\": [\n",
    "        (\"if 1 ≤ i ≤ 4, Y3(tv)\", 12),\n",
    "        (\"if i = 5, Y3(tv)\", 13),\n",
    "        (\"if i = 6, Y3(tv)\", 15),\n",
    "        (\"if i = 1, I(8 ≤ 7)Y3(tv)\", None),\n",
    "        (\"if 2 ≤ i ≤ 4, I(8 ≤ r_i)Y3(tv)\", 12),\n",
    "        (\"if i = 5, I(8 ≤ r5)Y3(tv)\", 13),\n",
    "        (\"if i = 6, I(8 ≤ r6)Y3(tv)\", 15),\n",
    "    ],\n",
    "    # OR4 = (3, 14]\n",
    "    \"(3, 14]\": [\n",
    "        (\"if 1 ≤ i ≤ 4, Y7(tv)\", 12),\n",
    "        (\"if i = 5, Y7(tv)\", 13),\n",
    "        (\"if i = 6, Y7(tv)\", 15),\n",
    "        (\"if i = 1, I(8 ≤ r1)Y7(tv)\", None),\n",
    "        (\"if 2 ≤ i ≤ 4, I(8 ≤ r_i)Y7(tv)\", 12),\n",
    "        (\"if i = 5, I(8 ≤ r5)Y7(tv)\", 13),\n",
    "        (\"if i = 6, I(8 ≤ r6)Y7(tv)\", 15),\n",
    "    ],\n",
    "    # OR5 = (3, 15]  (includes the “missing row” noted in the image)\n",
    "    \"(3, 15]\": [\n",
    "        (\"if 1 ≤ i ≤ 4, Y5(tv)\", 12),\n",
    "        (\"if i = 5, Y5(tv)\", 13),\n",
    "        (\"if i = 6, Y5(tv)\", 15),\n",
    "        (\"if i = 1, I(8 ≤ r1)Y5(tv)\", None),\n",
    "        (\"if 2 ≤ i ≤ 4, I(8 ≤ r_i)Y5(tv)\", 12),\n",
    "        (\"if i = 5, I(8 ≤ r5)Y5(tv)\", 13),\n",
    "        (\"if i = 6, I(8 ≤ r6)Y5(tv)\", 15),\n",
    "        (\"if i = 7, Y5(tv)\", 15),            # added row\n",
    "        (\"if i = 7, I(8 ≤ r7)Y5(tv)\", 15),   # indicator counterpart\n",
    "    ],\n",
    "    # OR9 = (7, 10] = (8,9] ∪ (9,10]\n",
    "    \"(7, 10]\": [\n",
    "        (\"i = 1 or 2, Y9(tv)\", 12),\n",
    "        (\"i = 1 or 2, I(8 ≤ r_i)Y9(tv)\", 12),\n",
    "    ],\n",
    "    # OR10 = (7, 15]\n",
    "    \"(7, 15]\": [\n",
    "        (\"1 ≤ i ≤ 3, Y10(tv)\", 12),\n",
    "        (\"i = 4, Y10(tv)\", 13),\n",
    "        (\"i = 5, Y10(tv)\", 15),\n",
    "        (\"i = 6, Y10(tv)\", 16),\n",
    "        (\"1 ≤ i ≤ 3, I(8 ≤ r_i)Y10(tv)\", 12),\n",
    "        (\"i = 4, I(8 ≤ r4)Y10(tv)\", 13),\n",
    "        (\"i = 5, I(8 ≤ r5)Y10(tv)\", 15),\n",
    "        (\"i = 6, I(8 ≤ r6)Y10(tv)\", 16),\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "def parse_probs(sum_breakdown: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Extract floats from a 'Sum breakdown' like '0.0437 + 0.0235 + ... = 0.296'.\n",
    "    Returns the list of component probabilities (unconditional).\n",
    "    \"\"\"\n",
    "    # The last number in the string is the '= total' — we only want the addends.\n",
    "    nums = [float(x) for x in re.findall(r\"\\d+\\.\\d+\", sum_breakdown)]\n",
    "    if len(nums) >= 2:\n",
    "        return nums[:-1]  # drop the final total on the right-hand side\n",
    "    return nums\n",
    "\n",
    "def conditional_cumulative(uncond: List[float], total: float) -> List[float]:\n",
    "    \"\"\"\n",
    "    Convert unconditional components -> cumulative conditional probabilities / total.\n",
    "    Last value forced to 1.0 (handles rounding noise).\n",
    "    \"\"\"\n",
    "    cs = np.cumsum(uncond, dtype=float)\n",
    "    cond = (cs / float(total)).tolist() if total != 0 else [0.0]*len(uncond)\n",
    "    if cond:\n",
    "        cond[-1] = 1.0\n",
    "    return cond\n",
    "\n",
    "def step_row(start_tv: int | None, tv_values: List[int]) -> List[int]:\n",
    "    \"\"\"Return a 0/1 row: 1 if tv >= start_tv; all zeros if start_tv is None.\"\"\"\n",
    "    if start_tv is None:\n",
    "        return [0] * len(tv_values)\n",
    "    return [1 if c >= start_tv else 0 for c in tv_values]\n",
    "\n",
    "def build_01_table(spec: List[Tuple[str, int | None]], tv_values: List[int]) -> pd.DataFrame:\n",
    "    \"\"\"Create a 0/1 step table from (label, start_tv) spec.\"\"\"\n",
    "    rows = {label: step_row(start, tv_values) for label, start in spec}\n",
    "    df = pd.DataFrame(rows, index=tv_values).T\n",
    "    df.index.name = \"draw\\\\tv\"\n",
    "    return df\n",
    "\n",
    "def safe_or_name(or_name: str) -> str:\n",
    "    \"\"\"Make a filesystem-friendly filename chunk from an OR string like '(1, 11]'.\"\"\"\n",
    "    return (\n",
    "        or_name.replace(\" \", \"\")\n",
    "        .replace(\",\", \"_\")\n",
    "        .replace(\"(\", \"\")\n",
    "        .replace(\")\", \"\")\n",
    "        .replace(\"]\", \"\")\n",
    "        .replace(\"[\", \"\")\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load Table 7\n",
    "    t7 = pd.read_csv(TABLE7_PATH)\n",
    "\n",
    "    # Build normalized prob table (long format across all ORs)\n",
    "    all_rows = []\n",
    "    for _, r in t7.iterrows():\n",
    "        or_name = str(r[\"Imp OR (L,R]\"]).strip()\n",
    "        total = float(r[\"Total probability (numeric)\"])\n",
    "        uncond = parse_probs(str(r[\"Sum breakdown\"]))\n",
    "        uncond_r = [round(x, 4) for x in uncond]\n",
    "        cond = [round(x, 6) for x in conditional_cumulative(uncond, total)]\n",
    "        for idx, (u, c) in enumerate(zip(uncond_r, cond), start=1):\n",
    "            all_rows.append(\n",
    "                {\"OR\": or_name, \"rect_idx\": idx, \"unconditional_prob\": u, \"conditional_cumprob\": c, \"total_prob\": total}\n",
    "            )\n",
    "\n",
    "    norm_df = pd.DataFrame(all_rows)\n",
    "    norm_df.to_csv(OUT_DIR / \"normalized_probs_all.csv\", index=False)\n",
    "\n",
    "    # Build and save 0/1 step tables for ORs we have specs for\n",
    "    for or_name, spec in tables_spec.items():\n",
    "        df01 = build_01_table(spec, tv_cols)\n",
    "        df01.to_csv(OUT_DIR / f\"table_{safe_or_name(or_name)}_01.csv\")\n",
    "\n",
    "    print(f\"Done. Wrote normalized probabilities and 0/1 tables to: {OUT_DIR.resolve()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba9a4b8-7484-4fcf-9b30-ebcdd7e823ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
